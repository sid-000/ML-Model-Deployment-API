# ğŸ§  ML Model Deployment API (FastAPI + Docker)

A production-ready API for serving machine learning model predictions using **FastAPI** and **Docker**. This project demonstrates how to load a trained ML model, expose it through a REST API, and containerize the entire system for reproducible deployment.

---

## ğŸš€ Features

- ğŸ§ª Trained ML model (Iris flower classifier)
- âš™ï¸ FastAPI-powered RESTful API
- ğŸ³ Dockerized for portable deployment
- ğŸ“„ Swagger UI for testing (`/docs`)
- âœ… Modular code: schema validation, routes, model loading
- ğŸ“‚ Output examples included (request/response, cURL, screenshots)

---

## ğŸ“ Project Structure
## ğŸ“‚ Folder Structure

```
ml-model-deployment-api/
â”œâ”€â”€ app/ # FastAPI app and logic
â”‚ â”œâ”€â”€ main.py
â”‚ â”œâ”€â”€ model/
â”‚ â”œâ”€â”€ routes/
â”‚ â””â”€â”€ schemas/
â”œâ”€â”€ training/ # Model training pipeline
â”‚ â”œâ”€â”€__init__.py
â”‚ â”œâ”€â”€config.py
â”‚ â”œâ”€â”€train_pipeline.py
â”‚ â””â”€â”€utils.py
â”œâ”€â”€ test/ # Tests (TBD)
â”œâ”€â”€ outputs/ # Screenshots and sample inputs
â”œâ”€â”€ Dockerfile # Docker container config
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md

```

---

## ğŸ“¦ Tech Stack

- Python 3.10
- FastAPI
- Scikit-learn
- Docker
- Pydantic
- Uvicorn

---

## ğŸ“Š Model Info

- Dataset: Iris (from `sklearn.datasets`)
- Model: `RandomForestClassifier` embedded in a `Pipeline` with `StandardScaler`
- Output: Predicted class label + class name

---

## ğŸŒ API Usage

### ğŸ”— **Endpoint**

**POST** `/api/predict`

---

### ğŸ“ **Sample Request**

```json
{
  "data": [5.1, 3.5, 1.4, 0.2]
}
```

---

### âœ… **Sample Response**

```json
{
  "prediction": 0,
  "class_name": "setosa"
}
```

---

## ğŸ§ª Run Locally

### 1ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 2ï¸âƒ£ Train the model

```bash
python -m training.train_pipeline
```

### 3ï¸âƒ£ Start the API

```bash
uvicorn app.main:app --reload
```

### 4ï¸âƒ£ Test in Swagger UI

[http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)

---

## ğŸ³ Run with Docker

### 1ï¸âƒ£ Build the image

```bash
docker build -t ml-api .
```

### 2ï¸âƒ£ Run the container

```bash
docker run -p 8000:8000 ml-api
```

Visit: [http://localhost:8000/docs](http://localhost:8000/docs)

---

## ğŸ–¼ï¸ Output Samples

```
ğŸ“ outputs/
â”œâ”€â”€ swagger_ui.png          â€“ Screenshot of Swagger
â”œâ”€â”€ predict_response.png    â€“ Sample model response
â”œâ”€â”€ sample_request.json     â€“ Example request payload
â”œâ”€â”€ sample_curl.txt         â€“ Example cURL command
```
